{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "from bytewax.dataflow import Dataflow\n",
    "from bytewax.inputs import Input\n",
    "from bytewax.outputs import Output\n",
    "from bytewax.testing import TestingInput\n",
    "from pydantic import parse_obj_as\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "from streaming_pipeline import mocked\n",
    "from streaming_pipeline.alpaca_batch import AlpacaNewsBatchInput\n",
    "from streaming_pipeline.alpaca_stream import AlpacaNewsStreamInput\n",
    "from streaming_pipeline.embeddings import EmbeddingModelSingleton\n",
    "from streaming_pipeline.models import NewsArticle\n",
    "from streaming_pipeline.qdrant import QdrantVectorOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_flow(\n",
    "    is_batch: bool = False,\n",
    "    from_datetime: Optional[datetime.datetime] = None,\n",
    "    to_datetime: Optional[datetime.datetime] = None,\n",
    "    model_cache_dir: Optional[Path] = None,\n",
    "    debug: bool = False,\n",
    ") -> Dataflow:\n",
    "    \"\"\"\n",
    "    Builds a dataflow pipeline for processing news articles.\n",
    "\n",
    "    Args:\n",
    "        is_batch (bool): Whether the pipeline is processing a batch of articles or a stream.\n",
    "        from_datetime (Optional[datetime.datetime]): The start datetime for processing articles.\n",
    "        to_datetime (Optional[datetime.datetime]): The end datetime for processing articles.\n",
    "        model_cache_dir (Optional[Path]): The directory to cache the embedding model.\n",
    "        debug (bool): Whether to enable debug mode.\n",
    "\n",
    "    Returns:\n",
    "        Dataflow: The dataflow pipeline for processing news articles.\n",
    "    \"\"\"\n",
    "\n",
    "    model = EmbeddingModelSingleton(cache_dir=model_cache_dir)\n",
    "    is_input_mocked = debug is True and is_batch is False\n",
    "\n",
    "    flow = Dataflow()\n",
    "    flow.input(\n",
    "        \"input\",\n",
    "        _build_input(\n",
    "            is_batch, from_datetime, to_datetime, is_input_mocked=is_input_mocked\n",
    "        ),\n",
    "    )\n",
    "    flow.flat_map(lambda messages: parse_obj_as(List[NewsArticle], messages))\n",
    "    if debug:\n",
    "        flow.inspect(print)\n",
    "    flow.map(lambda article: article.to_document())\n",
    "    flow.map(lambda document: document.compute_chunks(model))\n",
    "    flow.map(lambda document: document.compute_embeddings(model))\n",
    "    flow.output(\"output\", _build_output(model, in_memory=debug))\n",
    "\n",
    "    return flow\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "realtime_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
